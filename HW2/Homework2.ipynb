{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<h1>\n",
    "<center>CFRM 421/521, Spring 2022</center>\n",
    "</h1>\n",
    "\n",
    "<h1>\n",
    "<center>[Insert your name here]</center>\n",
    "</h1>\n",
    "\n",
    "<h1>\n",
    "<center>Homework 2</center>\n",
    "</h1>\n",
    "\n",
    "* **Due: Monday, May 2, 2022, 11:59 PM**\n",
    "\n",
    "\n",
    "* Total marks: 41\n",
    "\n",
    "\n",
    "* Late submissions are allowed, but a 20% penalty per day applies. Your last submission is considered for calculating the penalty.\n",
    "\n",
    "\n",
    "*  Use this Jupyter notebook as a template for your solutions. **Your solution must be submitted as one Jupyter notebook on Canvas and one PDF file on Gradescope.** The notebook must be already run, that is, make sure that you have run all your code, save the notebook, and then when you reopen the notebook, checked that all output appears as expected. You are allowed to use code from the textbook, textbook website, or lecture notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Random forest for time series data [13 marks]\n",
    "\n",
    "In this question you will work with the NYSE dataset. Only 3 time series in this dataset will be use: `DJ_return` ($a_t$), `log_volatility` ($b_t$), and `log_volume` ($c_t$). Download the data as a csv file from [Canvas](https://canvas.uw.edu/files/91091313/download?download_frd=1). The data was originally obtained from the R library ISLR2, and you can read the documentation for the dataset [here](https://cran.rstudio.com/web/packages/ISLR2/ISLR2.pdf), which explains the meaning of the variables.\n",
    "\n",
    "You want to predict the 1-step ahead value of `log_volume` $c_{t+1}$ using the previous values of this variable and the other two variables (`DJ_return` and `log_volatility`) up to 5 lags. So the features are $c_{t},\\dots,c_{t-4},b_{t},\\dots,b_{t-4},a_{t},\\dots,a_{t-4}$.\n",
    "\n",
    "If the data is stored in a file named `NYSE.csv` in your working directory, then loading the data can be done using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"NYSE.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) [3 marks]\n",
    "\n",
    "Create the feature matrix `X` and the target variable `y`. Print at least the first 2 rows of `X` and `y` (it is acceptable that not every element of the rows are printed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ts_split(ts, feature_steps=5, target_steps=1):\n",
    "    n_obs = len(ts) - feature_steps - target_steps + 1\n",
    "    X = np.array([ts[idx:idx + feature_steps] for idx in range(n_obs)])\n",
    "    y = np.array([ts[idx + feature_steps:idx + feature_steps + target_steps]\n",
    "                  for idx in range(n_obs)])\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "DJ_return = ts_split(data['DJ_return'])[0]\n",
    "log_volatility = ts_split(data['log_volatility'])[0]\n",
    "log_volume, y = ts_split(data['log_volume'])\n",
    "\n",
    "X =  np.hstack((log_volume, DJ_return, log_volatility))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 3.25730000e-02,  3.46202000e-01,  5.25306000e-01,\n         2.10182000e-01,  4.41870000e-02, -4.46100000e-03,\n         7.81300000e-03,  3.84500000e-03, -3.46200000e-03,\n         5.68000000e-04, -1.31274026e+01, -1.17493047e+01,\n        -1.16656090e+01, -1.16267724e+01, -1.17281302e+01],\n       [ 3.46202000e-01,  5.25306000e-01,  2.10182000e-01,\n         4.41870000e-02,  1.33246000e-01,  7.81300000e-03,\n         3.84500000e-03, -3.46200000e-03,  5.68000000e-04,\n        -1.08240000e-02, -1.17493047e+01, -1.16656090e+01,\n        -1.16267724e+01, -1.17281302e+01, -1.08725263e+01],\n       [ 5.25306000e-01,  2.10182000e-01,  4.41870000e-02,\n         1.33246000e-01, -1.15280000e-02,  3.84500000e-03,\n        -3.46200000e-03,  5.68000000e-04, -1.08240000e-02,\n         1.24000000e-04, -1.16656090e+01, -1.16267724e+01,\n        -1.17281302e+01, -1.08725263e+01, -1.09777968e+01],\n       [ 2.10182000e-01,  4.41870000e-02,  1.33246000e-01,\n        -1.15280000e-02,  1.60700000e-03, -3.46200000e-03,\n         5.68000000e-04, -1.08240000e-02,  1.24000000e-04,\n         3.35800000e-03, -1.16267724e+01, -1.17281302e+01,\n        -1.08725263e+01, -1.09777968e+01, -1.10123599e+01],\n       [ 4.41870000e-02,  1.33246000e-01, -1.15280000e-02,\n         1.60700000e-03, -1.06437000e-01,  5.68000000e-04,\n        -1.08240000e-02,  1.24000000e-04,  3.35800000e-03,\n        -3.29600000e-03, -1.17281302e+01, -1.08725263e+01,\n        -1.09777968e+01, -1.10123599e+01, -1.10471081e+01],\n       [ 1.33246000e-01, -1.15280000e-02,  1.60700000e-03,\n        -1.06437000e-01, -1.38269000e-01, -1.08240000e-02,\n         1.24000000e-04,  3.35800000e-03, -3.29600000e-03,\n         4.46900000e-03, -1.08725263e+01, -1.09777968e+01,\n        -1.10123599e+01, -1.10471081e+01, -1.10220634e+01],\n       [-1.15280000e-02,  1.60700000e-03, -1.06437000e-01,\n        -1.38269000e-01, -4.96350000e-02,  1.24000000e-04,\n         3.35800000e-03, -3.29600000e-03,  4.46900000e-03,\n        -4.02000000e-03, -1.09777968e+01, -1.10123599e+01,\n        -1.10471081e+01, -1.10220634e+01, -1.10231535e+01],\n       [ 1.60700000e-03, -1.06437000e-01, -1.38269000e-01,\n        -4.96350000e-02, -4.33870000e-02,  3.35800000e-03,\n        -3.29600000e-03,  4.46900000e-03, -4.02000000e-03,\n        -8.32300000e-03, -1.10123599e+01, -1.10471081e+01,\n        -1.10220634e+01, -1.10231535e+01, -1.07421494e+01],\n       [-1.06437000e-01, -1.38269000e-01, -4.96350000e-02,\n        -4.33870000e-02,  5.36290000e-02, -3.29600000e-03,\n         4.46900000e-03, -4.02000000e-03, -8.32300000e-03,\n         1.06590000e-02, -1.10471081e+01, -1.10220634e+01,\n        -1.10231535e+01, -1.07421494e+01, -1.03875009e+01],\n       [-1.38269000e-01, -4.96350000e-02, -4.33870000e-02,\n         5.36290000e-02,  1.04624000e-01,  4.46900000e-03,\n        -4.02000000e-03, -8.32300000e-03,  1.06590000e-02,\n         2.39300000e-03, -1.10220634e+01, -1.10231535e+01,\n        -1.07421494e+01, -1.03875009e+01, -1.04724269e+01]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.133246],\n       [-0.011528],\n       [ 0.001607],\n       [-0.106437],\n       [-0.138269],\n       [-0.049635],\n       [-0.043387],\n       [ 0.053629],\n       [ 0.104624],\n       [-0.088976]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)  [4 marks]\n",
    "\n",
    "Consider fitting a random forest to predict the 1-step ahead value of `log_volume`. The random forest must include the argument `random_state=42`, and it is useful to also include `n_jobs=-1` (you can use `n_job=-1` throughout this homework wherever it is avaliable). Use 3-fold time series CV, with the test set split 50% into a validation set and 50% into the actual test set, to tune the hyperparameters `n_estimators` taking the values  100, 500, 750, and the cost-complexity pruning parameter $\\alpha$ taking the values $10^{-k}$, $k=0,1,\\dots,9$. The performance measure is RMSE. Report the best hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "series_len = y.size\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Hyperparamter combinations\n",
    "n_estimators_list = [100, 500, 750]\n",
    "ccp_alpha_list = 10**(-np.arange(0, 10).astype(float))\n",
    "\n",
    "def time_series_valid_test(X, y, n_split, valid_or_test, optimal_par=None):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_split)\n",
    "    rf_rmse = []\n",
    "    i = 0\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        i += 1\n",
    "        # Break test set into 50% validation set, 50% test set\n",
    "        break_test_ind = int(test_index[0] + 0.5*(test_index[-1]-test_index[0]))\n",
    "        valid_index = np.array(list(range(test_index[0],break_test_ind)))\n",
    "        test_index = np.array(list(range(break_test_ind,test_index[-1])))\n",
    "\n",
    "        # Split\n",
    "        X_train, X_valid, X_test = X[train_index], X[valid_index], X[test_index]\n",
    "        y_train, y_valid, y_test = y[train_index], y[valid_index], y[test_index]\n",
    "\n",
    "        # Tuning\n",
    "        if valid_or_test == \"valid\":\n",
    "            for n_estimators in n_estimators_list:\n",
    "                for ccp_alpha in ccp_alpha_list:\n",
    "                    model_rf = RandomForestRegressor(random_state=42,\n",
    "                               n_estimators=n_estimators, ccp_alpha=ccp_alpha, n_jobs=-1)\n",
    "                    model_rf.fit(X_train, y_train.ravel())\n",
    "                    y_val_rf = model_rf.predict(X_valid)\n",
    "                    rf_rmse.append(np.sqrt(mean_squared_error(y_valid, y_val_rf)))\n",
    "\n",
    "        # Evalulate on test set\n",
    "        if valid_or_test == \"test\":\n",
    "            model_rf = RandomForestRegressor(random_state=42,\n",
    "                       n_estimators=optimal_par[0], ccp_alpha=optimal_par[1], n_jobs=-1)\n",
    "            model_rf.fit(X_train, y_train.ravel())\n",
    "            y_test_rf = model_rf.predict(X_test)\n",
    "            rf_rmse.append(np.sqrt(mean_squared_error(y_test, y_test_rf)))\n",
    "\n",
    "            # Plot the prediction for the last CV fold\n",
    "            if i == n_split:\n",
    "                plt.plot(range(series_len-test_index.size,series_len),\n",
    "                         y_test_rf, label=\"1-step ahead prediction\")\n",
    "                plt.plot(range(series_len-test_index.size,series_len),\n",
    "                         y_test, label=\"True value\")\n",
    "                plt.legend(loc=\"upper left\")\n",
    "\n",
    "    # Average RMSE over CV folds\n",
    "    if valid_or_test == \"valid\":\n",
    "        rf_rmse = np.mean(np.array(rf_rmse).reshape(\n",
    "            n_split, len(n_estimators_list)*len(ccp_alpha_list)), axis=0)\n",
    "        return rf_rmse\n",
    "    if valid_or_test == \"test\":\n",
    "        rf_rmse = np.mean(rf_rmse)\n",
    "        return rf_rmse, y_test_rf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(n_estimators, ccp_alpha):', [100, 1.0]]\n",
      "0.2358102502325389\n",
      "['(n_estimators, ccp_alpha):', [100, 0.1]]\n",
      "0.2358102502325389\n",
      "['(n_estimators, ccp_alpha):', [100, 0.01]]\n",
      "0.1931776501341703\n",
      "['(n_estimators, ccp_alpha):', [100, 0.001]]\n",
      "0.1742571823815323\n",
      "['(n_estimators, ccp_alpha):', [100, 0.0001]]\n",
      "0.1614501523436291\n",
      "['(n_estimators, ccp_alpha):', [100, 1e-05]]\n",
      "0.16092212183444374\n",
      "['(n_estimators, ccp_alpha):', [100, 1e-06]]\n",
      "0.16126901713458971\n",
      "['(n_estimators, ccp_alpha):', [100, 1e-07]]\n",
      "0.16132852989129298\n",
      "['(n_estimators, ccp_alpha):', [100, 1e-08]]\n",
      "0.16134226586644118\n",
      "['(n_estimators, ccp_alpha):', [100, 1e-09]]\n",
      "0.1613426447569936\n",
      "['(n_estimators, ccp_alpha):', [500, 1.0]]\n",
      "0.23583279057420017\n",
      "['(n_estimators, ccp_alpha):', [500, 0.1]]\n",
      "0.23583279057420017\n",
      "['(n_estimators, ccp_alpha):', [500, 0.01]]\n",
      "0.19289278821198516\n",
      "['(n_estimators, ccp_alpha):', [500, 0.001]]\n",
      "0.1741139415851224\n",
      "['(n_estimators, ccp_alpha):', [500, 0.0001]]\n",
      "0.16109603191941044\n",
      "['(n_estimators, ccp_alpha):', [500, 1e-05]]\n",
      "0.1603712805479507\n",
      "['(n_estimators, ccp_alpha):', [500, 1e-06]]\n",
      "0.16049475493676732\n",
      "['(n_estimators, ccp_alpha):', [500, 1e-07]]\n",
      "0.16048907831763903\n",
      "['(n_estimators, ccp_alpha):', [500, 1e-08]]\n",
      "0.16048958413764564\n",
      "['(n_estimators, ccp_alpha):', [500, 1e-09]]\n",
      "0.16049050149964617\n",
      "['(n_estimators, ccp_alpha):', [750, 1.0]]\n",
      "0.23582412722547763\n",
      "['(n_estimators, ccp_alpha):', [750, 0.1]]\n",
      "0.23582412722547763\n",
      "['(n_estimators, ccp_alpha):', [750, 0.01]]\n",
      "0.1928692930007393\n",
      "['(n_estimators, ccp_alpha):', [750, 0.001]]\n",
      "0.17402380547187205\n",
      "['(n_estimators, ccp_alpha):', [750, 0.0001]]\n",
      "0.16119411919288015\n",
      "['(n_estimators, ccp_alpha):', [750, 1e-05]]\n",
      "0.1604152297725059\n",
      "['(n_estimators, ccp_alpha):', [750, 1e-06]]\n",
      "0.1605662577364352\n",
      "['(n_estimators, ccp_alpha):', [750, 1e-07]]\n",
      "0.16056965853925861\n",
      "['(n_estimators, ccp_alpha):', [750, 1e-08]]\n",
      "0.16057080772829083\n",
      "['(n_estimators, ccp_alpha):', [750, 1e-09]]\n",
      "0.1605705435233036\n"
     ]
    }
   ],
   "source": [
    "rf_rmse = time_series_valid_test(X, y, 3, \"valid\")\n",
    "ind = 0\n",
    "for n_estimators in n_estimators_list:\n",
    "    for ccp_alpha in ccp_alpha_list:\n",
    "        print([\"(n_estimators, ccp_alpha):\",[n_estimators, ccp_alpha]])\n",
    "        print(rf_rmse[ind])\n",
    "        ind += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(n_estimators, ccp_alpha):', [500, 1e-05]]\n"
     ]
    }
   ],
   "source": [
    "print([\"(n_estimators, ccp_alpha):\",[500, 1e-05]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)  [2 marks]\n",
    "\n",
    "Using the same time series split as in (b), compute the RMSE of the best fitting model on the test set, and include a plot of the true values and predicted values on the test set of the last fold (the fold closest to the current time) of the CV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0.18695778279368594"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_rmse, y_test_rf = time_series_valid_test(X, y, 3, \"test\", [500, 1e-05])\n",
    "rf_rmse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) [2 marks]\n",
    "\n",
    "It is often useful to check that your model is not worse than a very simple method of prediction. Compute the RMSE of a model that simply predicts the 1-step ahead value of `log_volume` $c_{t+1}$ as the current value $c_t$, and compare this to the best fitting random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0.18886372498700638"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rmse = np.sqrt(mean_squared_error(y[1:], y[0:-1]))\n",
    "simple_rmse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) [2 marks]\n",
    "\n",
    "Compute the feature importances of the best fitting model. Which feature is the most important and what is its feature importance value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.05910464, 0.06276926, 0.04343883, 0.03711868, 0.52845434,\n       0.03368364, 0.02979753, 0.03728229, 0.03897922, 0.06402235,\n       0.01548615, 0.01227923, 0.01110293, 0.0125332 , 0.0139477 ])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = RandomForestRegressor(random_state=42,\n",
    "           n_estimators=500, ccp_alpha=1e-05, n_jobs=-1)\n",
    "best_model.fit(X, y.ravel())\n",
    "\n",
    "best_model.feature_importances_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5284543420578321"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(best_model.feature_importances_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "the current value of log_volume"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SVM classification and regression [11 marks]\n",
    "\n",
    "## (a) [2 marks]\n",
    "\n",
    "In this question, a SVM is used for classification for the MNIST dataset. The following code loads the MNIST dataset, creates the test set, and to reduce training time, takes a random sample of 2000 points from the full training set to use as your actual training set stored in `X` and `y`. Do not shuffle the data and do not use a standard scaler.\n",
    "\n",
    "Hint: Reading the solution to Question 9 in the Chapter 5 [Jupyter notebook](https://github.com/ageron/handson-ml2/blob/master/05_support_vector_machines.ipynb) on the textbook website may help with this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, cache=True)\n",
    "mnist.target = mnist.target.astype(np.int8)\n",
    "X_train = mnist[\"data\"][:60000]\n",
    "X_test  = mnist[\"data\"][60000:]\n",
    "y_train = mnist[\"target\"][:60000]\n",
    "y_test  = mnist[\"target\"][60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "N = 2000\n",
    "split_obj = StratifiedShuffleSplit(n_splits=1,\n",
    "                               test_size=N/60000, random_state=42)\n",
    "for other_idx, subsample_idx in split_obj.split(X_train, y_train):\n",
    "    X = X_train[subsample_idx]\n",
    "    y = y_train[subsample_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Consider fitting the linear SVM classifier (`LinearSVC`) with `max_iter=50000`. For this model, optimize the hyperparameter $C$ using 3-fold CV over the values $10^{-k}$, $k=0,1,\\dots,9$, where the performance measure is accuracy. What is the best $C$ and what is the accuracy in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=3,\n             estimator=LinearSVC(loss='hinge', max_iter=50000, random_state=42),\n             n_jobs=-1,\n             param_grid={'C': [1.0, 0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06,\n                               1e-07, 1e-08, 1e-09]},\n             scoring='accuracy')"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "     'C': list(10**(-np.arange(0, 10).astype(float)))\n",
    "  }\n",
    "\n",
    "svm_clf = LinearSVC(loss='hinge', max_iter=50000, random_state=42)\n",
    "grid_search = GridSearchCV(svm_clf, param_grid, cv=3,\n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1)\n",
    "grid_search.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'C': 1e-06}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8569941755848802"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) [2 marks]\n",
    "\n",
    "**Task:** Now consider fitting a SVM with a Gaussian RBF kernel and `max_iter=50000`. For this model, optimize the hyperparameters $C$ over the distrbution `uniform(1,10)` and $\\gamma$ over the distribution `reciprocal(0.001, 0.1)` with 10 random samples. Again, use 3-fold CV and the performance measure is accuracy. What are the best hyperparameters and what is the accuracy in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=3, estimator=SVC(max_iter=50000), n_jobs=-1,\n                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000176D4935D30>,\n                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000176D477D1F0>},\n                   random_state=42, scoring='accuracy')"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import reciprocal\n",
    "\n",
    "param_distribs = {\n",
    "        'C': uniform(1, 10),\n",
    "        'gamma': reciprocal(0.001, 0.1),\n",
    "    }\n",
    "\n",
    "svm_rbf = SVC(max_iter=50000, kernel='rbf')\n",
    "rnd_search = RandomizedSearchCV(svm_rbf, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=3, scoring='accuracy', random_state=42,\n",
    "                                n_jobs=-1)\n",
    "rnd_search.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "{'C': 4.745401188473625, 'gamma': 0.07969454818643928}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.11250005627816723"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) [2 mark]\n",
    "\n",
    "**Task:** Choose the best model in (a) and (b). Then for this model, evaluate the accuracy on the test set, which is stored in `X_test` and `y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8855"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) [3 marks]\n",
    "\n",
    "Consider the California housing data from Homework 1 using the same training and test set there. The data is obtained using the code below, which comes from Homework 1, and the training set is stored in `X` and `y`. Do not shuffle the data.\n",
    "\n",
    "Hint: Reading the solution to Question 10 in the Chapter 5 [Jupyter notebook](https://github.com/ageron/handson-ml2/blob/master/05_support_vector_machines.ipynb) on the textbook website may help with this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "\n",
    "def fetch_housing_data(housing_url, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "HOUSING_URL = (\"https://raw.githubusercontent.com/ageron/\"+\n",
    "               \"handson-ml2/master/datasets/housing/housing.tgz\")\n",
    "fetch_housing_data(HOUSING_URL)\n",
    "data = load_housing_data()\n",
    "\n",
    "data[\"income_cat\"] = np.ceil(data[\"median_income\"] / 1.5)\n",
    "data[\"income_cat\"].where(data[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(data, data[\"income_cat\"]):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "X_raw = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "y = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "num_features = X_raw.drop(\"ocean_proximity\", axis=1)\n",
    "num_attribs = list(num_features)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "X = full_pipeline.fit_transform(X_raw)\n",
    "X_test_raw = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "X_test = full_pipeline.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Consider SVM regression with a Gaussian RBF kernel and a sigmoid kernel with `max_iter=50000`. For both models, use randomized search to choose good hyperparameter values for `C` and `gamma`, and set the arguement `random_state=42`. For both models, optimize the hyperparameters $C$ over the distrbution `uniform(1,10)` and $\\gamma$ over the distribution `reciprocal(0.001, 0.1)` with 10 random samples. Again, use 3-fold CV and the performance measure is MSE. What are the best hyperparameters and what is the MSE in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=3, estimator=SVR(max_iter=50000), n_jobs=-1,\n                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000176D4997A90>,\n                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000176D477D7C0>},\n                   random_state=42, scoring='neg_mean_squared_error')"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "param_distribs = {\n",
    "        'C': uniform(1, 10),\n",
    "        'gamma': reciprocal(0.001, 0.1),\n",
    "    }\n",
    "\n",
    "svr_rbf = SVR(max_iter=50000, kernel='rbf')\n",
    "rnd_search_rbf = RandomizedSearchCV(svr_rbf, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=3, scoring='neg_mean_squared_error', random_state=42,\n",
    "                                n_jobs=-1)\n",
    "rnd_search_rbf.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "{'C': 4.745401188473625, 'gamma': 0.07969454818643928}"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_rbf.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "13877012057.239176"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-rnd_search_rbf.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=3, estimator=SVR(kernel='sigmoid', max_iter=50000),\n                   n_jobs=-1,\n                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000176D4935400>,\n                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000176D4935700>},\n                   random_state=42, scoring='neg_mean_squared_error')"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distribs = {\n",
    "        'C': uniform(1, 10),\n",
    "        'gamma': reciprocal(0.001, 0.1),\n",
    "    }\n",
    "\n",
    "svr_sig = SVR(max_iter=50000, kernel='sigmoid')\n",
    "rnd_search_sig = RandomizedSearchCV(svr_sig, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=3, scoring='neg_mean_squared_error', random_state=42,\n",
    "                                n_jobs=-1)\n",
    "rnd_search_sig.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "{'C': 4.745401188473625, 'gamma': 0.07969454818643928}"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_sig.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "13744315287.792427"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-rnd_search_sig.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) [2 marks]\n",
    "\n",
    "**Task:** Choose the best model in (d). Then for this model, evaluate the RMSE on the test set, which is stored in `X_test` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "114741.28850451492"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = rnd_search_sig.best_estimator_.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Voting Classifiers [8 marks]\n",
    "## (a)  [4 marks]\n",
    "\n",
    "Consider the MNIST dataset. To save computational time, split it into a smaller training set (the first 5000 observations) and a validation set (the next 1000 observations) as given by the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "M = 6000\n",
    "X_train = mnist[\"data\"][:N]\n",
    "X_val  = mnist[\"data\"][N:M]\n",
    "y_train = mnist[\"target\"][:N]\n",
    "y_val = mnist[\"target\"][N:M]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not shuffle the data and do not use a standard scaler. Train the following classifiers on the training set:\n",
    "\n",
    "(i) a random forest classifier with arguments `n_estimators=100, n_jobs=-1, random_state=42`,\n",
    "\n",
    "(ii) an extra-trees classifier with arguments `n_estimators=100, n_jobs=-1, random_state=42`,\n",
    "\n",
    "(iii) an AdaBoost classifier `n_estimators=50, learning_rate=0.2, random_state=42`,\n",
    "\n",
    "(iv) a gradient boosting classifier using the class `GradientBoostingClassifier()` with arguments `max_depth=2, n_estimators=10, learning_rate=0.25, random_state=42`.\n",
    "\n",
    "Report the accuracy of each trained classifier on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingClassifier(learning_rate=0.25, max_depth=2, n_estimators=10,\n                           random_state=42)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "et_clf = ExtraTreesClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "ab_clf = AdaBoostClassifier(n_estimators=50, learning_rate=0.2, random_state=42)\n",
    "gb_clf = GradientBoostingClassifier(max_depth=2, n_estimators=10, learning_rate=0.25, random_state=42)\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "et_clf.fit(X_train, y_train)\n",
    "ab_clf.fit(X_train, y_train)\n",
    "gb_clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "y_pred_rf = rf_clf.predict(X_val)\n",
    "y_pred_et = et_clf.predict(X_val)\n",
    "y_pred_ab = ab_clf.predict(X_val)\n",
    "y_pred_gb = gb_clf.predict(X_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "0.939"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_rf, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "0.947"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_et, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "0.736"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_ab, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "0.834"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_gb, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)  [4 marks]\n",
    "Train a hard-voting and a soft-voting ensemble classifier based on the models in (a). Evaluate each voting classifier on the validation set. Comment on whether the performance of the ensemble model is better or worse than the individual models in (a) and why that is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf_hard = VotingClassifier(\n",
    "    estimators=[('rf', rf_clf), ('et', et_clf), ('ab', ab_clf), ('gb', gb_clf)],\n",
    "    voting='hard')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "VotingClassifier(estimators=[('rf',\n                              RandomForestClassifier(n_jobs=-1,\n                                                     random_state=42)),\n                             ('et',\n                              ExtraTreesClassifier(n_jobs=-1, random_state=42)),\n                             ('ab',\n                              AdaBoostClassifier(learning_rate=0.2,\n                                                 random_state=42)),\n                             ('gb',\n                              GradientBoostingClassifier(learning_rate=0.25,\n                                                         max_depth=2,\n                                                         n_estimators=10,\n                                                         random_state=42))])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf_hard.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "0.923"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_hard = voting_clf_hard.predict(X_val)\n",
    "accuracy_score(y_pred_hard, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "voting_clf_soft = VotingClassifier(\n",
    "    estimators=[('rf', rf_clf), ('et', et_clf), ('ab', ab_clf), ('gb', gb_clf)],\n",
    "    voting='soft')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "VotingClassifier(estimators=[('rf',\n                              RandomForestClassifier(n_jobs=-1,\n                                                     random_state=42)),\n                             ('et',\n                              ExtraTreesClassifier(n_jobs=-1, random_state=42)),\n                             ('ab',\n                              AdaBoostClassifier(learning_rate=0.2,\n                                                 random_state=42)),\n                             ('gb',\n                              GradientBoostingClassifier(learning_rate=0.25,\n                                                         max_depth=2,\n                                                         n_estimators=10,\n                                                         random_state=42))],\n                 voting='soft')"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf_soft.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "0.926"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_soft = voting_clf_soft.predict(X_val)\n",
    "accuracy_score(y_pred_soft, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Stacking [9 marks]\n",
    "\n",
    "We continue with the setting of Question 3. The training set, validation set and test set are the same. In Question 3, we have used predetermined rules (that is, hard-voting and soft-voting) to build the ensemble prediction. **Stacking** is an ensemble method in which you train a model (called a **blender**) to aggregate the result of each predictor into an ensemble prediction.\n",
    "\n",
    "Hint: Reading the subsection \"Stacking\" in Chapter 7 of the textbook and the solution to Question 9 in the Chapter 7 [Jupyter notebook](https://github.com/ageron/handson-ml2/blob/master/07_ensemble_learning_and_random_forests.ipynb) on the textbook website may help with this question.\n",
    "\n",
    "## (a)  [3 marks]\n",
    "\n",
    "For each of the four classifiers in Question 3(a), make 5000 clean predictions on the training set with 3-fold cross validation using `sklearn.model_selection.cross_val_predict()`. You should end up with four predictions per observation. Print at least the first 5 rows of `pred`. Next, apply one-hot encoding to `pred` since these predictions are class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "rf_pred = cross_val_predict(rf_clf, X_train, y_train, cv=3,  n_jobs=-1)\n",
    "et_pred = cross_val_predict(et_clf, X_train, y_train, cv=3,  n_jobs=-1)\n",
    "ab_pred = cross_val_predict(ab_clf, X_train, y_train, cv=3,  n_jobs=-1)\n",
    "gb_pred = cross_val_predict(gb_clf, X_train, y_train, cv=3,  n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5, 5, 3, 3],\n       [0, 0, 5, 0],\n       [4, 4, 4, 4],\n       [1, 1, 1, 1],\n       [9, 9, 9, 9],\n       [2, 2, 2, 2],\n       [1, 1, 1, 1],\n       [3, 3, 3, 3],\n       [1, 1, 1, 1],\n       [4, 4, 4, 4]], dtype=int8)"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred =  np.stack((rf_pred, et_pred, ab_pred, gb_pred), axis=1)\n",
    "pred[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 1., 0., 0., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 1., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        1., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 1., 0., 0., 0., 0., 0.]])"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder(sparse=False)\n",
    "pred = cat_encoder.fit_transform(pred)\n",
    "pred[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) [3 marks]\n",
    "Use the predictions in (a) as features and the actual label of the observations as the target. Train a random forest classifier on the training set with the parameters `n_estimators=100, random_state=42`.  This classifier is a blender. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(random_state=42)"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blender = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "blender.fit(pred, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) [3 marks]\n",
    "\n",
    "Obtain the predictions of the blender on the validation set by feeding predictions on the validation set from the four classifiers in Question 3(a) into the blender trained in Question 4(b). Do not retrain the blender. These are called stacking predictions. Report the accuracy of your stacking predictions on the validation set and compare this to the results in Question 3(b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Add your solution here]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "rf_pred_val = rf_clf.predict(X_val)\n",
    "et_pred_val = et_clf.predict(X_val)\n",
    "ab_pred_val = ab_clf.predict(X_val)\n",
    "gb_pred_val = gb_clf.predict(X_val)\n",
    "\n",
    "pred_val =  np.stack((rf_pred_val, et_pred_val, ab_pred_val, gb_pred_val), axis=1)\n",
    "pred_val = cat_encoder.transform(pred_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "stacking_pred = blender.predict(pred_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "0.947"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(stacking_pred, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}